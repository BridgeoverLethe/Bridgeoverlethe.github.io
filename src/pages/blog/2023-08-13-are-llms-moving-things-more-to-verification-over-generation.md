---
title: Are LLMs moving things more to verification over generation?
description: If its easier to generate content, then is the work going to verifying content? AKA science?
pubDate: 2023-08-13T18:32:45.142Z
preview: ""
draft: true
tags:
  - AI
  - LLM
  - Economics
categories:
  - Musings
slug: llms-moving-verification-generation
---

Pretty much what it says on the tin. I can use an LLM to punch out a page of text, and then tweak it to match what I think should be good.

But you don't typically write in a vaccum. Someone else is usualy going to read it. 

More importantly, when *you* get content, you need to verify if it makes sense and is applicable. 

Its the mastery verification problem. Train people at scale, recruiting good talent - all of it is a Hard problem. You have verify if someone has actually learnt anything. 

Theres always a proxy to mastery, but if you know the proxy in advance, you can just master the proxy. Time and effort saved.

Its why education is always about tests, projects or other ways to check if the student *gets it*

When you have a lot of people, millions upon millions, then you probably won't have enough teachers for that population. Which means projects are not really going to be ccovered fast enough. You then just have exams, lots of em.

LLMs make several of the more routine text focused tasks easier. They also open you up to the problem of verifiying whether that text is actaully right. 

Coincidentally, testing a hypothesis and adding to the knowledge of the world is the crux of doing good science.

FINE its late, im rambling. Somehow I am missing the exact words that connect the points. 

Imagine you are sitting at your PC, you get a new email, or you use an LLM to generate some content. It has saved you hours of work doing it yourself. 

How do you *know* its correct?

This scenario is the crux of it. 

Anwyays, I am going to sleep. Lets see if Front Matter works